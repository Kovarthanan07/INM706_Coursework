{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec558c44",
   "metadata": {},
   "source": [
    "## Setting up the dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c50614e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_auc_score, roc_curve\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from tqdm import tqdm\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2cd54f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "Loading both abnormal and normal datasets.\n",
    "\"\"\"\n",
    "\n",
    "normal_df = pd.read_csv(\"dataset/ptbdb_normal.csv\").iloc[:, :-1]\n",
    "abnormal_df = pd.read_csv(\n",
    "    \"dataset/ptbdb_abnormal.csv\").iloc[:, :-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b1fe7750",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "To fix the imbalance, Trimming the abnormal set\n",
    "\"\"\"\n",
    "\n",
    "anomaly_df = abnormal_df.sample(n=2000, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a646f76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "Dataset converted to numpy\n",
    "\"\"\"\n",
    "normal = normal_df.to_numpy()\n",
    "anomaly = anomaly_df.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f21242c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "Dataset split\n",
    "\"\"\"\n",
    "\n",
    "X_train, X_test = train_test_split(normal, test_size=0.15, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6ef15797",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "Custom dataset class for ECG Data \n",
    "\"\"\"\n",
    "\n",
    "class ECGDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = torch.tensor(data, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx], self.data[idx]  # AutoEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "40ce35f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "Setting up dataloaders\n",
    "\"\"\"\n",
    "\n",
    "train_loader = DataLoader(ECGDataset(X_train), batch_size=128, shuffle=True)\n",
    "test_loader = DataLoader(ECGDataset(X_test), batch_size=128)\n",
    "anomaly_loader = DataLoader(ECGDataset(anomaly), batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e223c6ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "Defining the AutoEnoder model. \n",
    "including both encoder and decoder\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "class Conv1DAutoEncoder(nn.Module):\n",
    "    def __init__(self, input_dim, latent_dim=32):\n",
    "        super(Conv1DAutoEncoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv1d(1, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.MaxPool1d(2),\n",
    "            nn.Conv1d(128, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.MaxPool1d(2),\n",
    "            nn.Conv1d(128, latent_dim, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(latent_dim),\n",
    "            nn.MaxPool1d(2),\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose1d(latent_dim, latent_dim,\n",
    "                               kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(latent_dim),\n",
    "            nn.ConvTranspose1d(latent_dim, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ConvTranspose1d(128, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear((input_dim//8)*128, input_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(1)\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080a7cce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
